import chromadb
from sentence_transformers import SentenceTransformer
from google import genai
import ast
import mysql_connect

api = genai.Client(api_key="AIzaSyCgW7EQ2Ux8RobPW8uQtz7mq2HDFKnVlas")
gemini_prompt = """You are Patuta, a climate analyser focused on fossil fuel emissions.  
                    Guidelines:
                    - Answer concisely, summarise, and use bullet points if needed.  
                    - Always sound natural and human.  
                    - Never mention storage details (e.g., SQL, database).  
                    - If the answer is large → break into readable bullet points or a short paragraph.  
                    - If data is missing, say "No data provided" (never hallucinate).  
                    - Respond naturally to greetings or unrelated queries.  """

client = chromadb.PersistentClient(path="chroma_db")
collection = client.get_collection(name="fossil_fuel_emissions")

model = SentenceTransformer('all-MiniLM-L6-v2')

def retrieve(query):
    response = api.models.generate_content(
        model="gemini-2.5-flash",
        contents = [
        f"{query}\n",
        """Query: {query}
        basic intructions:{gemini_prompt}
        Return JSON as a list: ["true"|"false"|"neutral", "<rewritten query or SQL or response>"]

        Rules:
        - "true": if query is descriptive/semantic → rewrite the query.  
        - "false": if query asks for numeric analysis (highest, lowest, trend, difference,etc) → return SQL for table fossil_fuel(year, emissions, longitude, latitude, change, pct_change).  
        - "neutral": if general (hi, bye, etc) → respond naturally.  """

    ]

    )
    query_embedding = model.encode(m[1]).tolist()
    def clean_response(text):
    # remove markdown fences like ```json ... ```
        return text.strip().removeprefix("```json").removesuffix("```").strip()
    r = clean_response(response.text)
    m = ast.literal_eval(r)
# print(m[0])
    if m[0] == "true":
        # print(m[0])
        ai_response_embedding = model.encode(m).tolist()
        # some_query_embedding = model.encode("Always give the latest data").tolist()

        restults = collection.query(
        query_embeddings=[query_embedding, ai_response_embedding],
        n_results=10)

        res = api.models.generate_content(
        model="gemini-2.5-flash",
        contents=[
            f"{query}\n",
            f"{m[1]}\n",
            f"{restults}",
            """Query: {query}  
            Rewritten Query: {m[1]}  
            Results: {results}  

            Task: Analyse the results and answer.  
            - Be concise, natural, and human-like.  
            - Never mention databases or storage.  
            - If answer is long, summarise in bullet points or short paragraph.  
            - If no answer → say "No data provided".  """])
    elif m[0] == "false":
        # print(m[0])
        sql_query = m[1]
        print(sql_query)
        data = mysql_connect.getdata(sql_query)

        system_prompt = """Query: {query}  
        Data: {data}  

        Task: Analyse the data and respond.  
        - Write a clear, human-readable explanation.  
        - Never say "single data point".  
        - Keep it concise and natural.  
        - Use bullet points if helpful.  """
        res = api.models.generate_content(
            model="gemini-2.5-flash",
            contents=[system_prompt]
        )
        return res.text.replace("*", "")
    else:
        return m[1].replace("*", "")
    

# query_s = input("Enter your query: ")
# while query_s != "exit":
#     print(retrieve(query_s))
#     query_s = input("Enter your query: ")
# l = "which year had the highest emissions of fossil fuel CO2?"

# print(retrieve(l))